{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgv6eKRKVy4FBe9S2JoanY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul99-collab/DUO-CONNECT/blob/main/PreprocessAndSpiltting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz0FwCh-c-Fm",
        "outputId": "dd1b3ff2-f353-4c2a-8cf3-eaa6750ae265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python numpy tqdm moviepy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2ljFOHadLrD",
        "outputId": "daa72bf6-1f33-4ff3-93b5-fad68116d9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "video_folder = \"/content/drive/MyDrive/deepfake\"  # Folder where 60 videos are stored\n",
        "output_frames = \"/content/drive/MyDrive/Extracted frames\"  # Extracted frames\n",
        "output_preprocessed = \"/content/drive/MyDrive/Preprocessed frames\"  # Preprocessed frames\n",
        "split_dataset_path = \"/content/drive/MyDrive/Final dataset split\"  # Train/Val/Test folders\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(output_frames, exist_ok=True)\n",
        "os.makedirs(output_preprocessed, exist_ok=True)\n",
        "os.makedirs(split_dataset_path, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "DKtPUu9RdU1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "\n",
        "def extract_frames_from_videos(video_folder, output_folder, frame_rate=1):\n",
        "    \"\"\"\n",
        "    Extract frames from multiple videos and save them as images.\n",
        "    - video_folder: Folder containing videos.\n",
        "    - output_folder: Where to save extracted frames.\n",
        "    - frame_rate: Frames per second to extract.\n",
        "    \"\"\"\n",
        "    video_files = glob.glob(os.path.join(video_folder, \"*.mp4\"))  # Get all videos\n",
        "    print(f\"Found {len(video_files)} videos.\")\n",
        "\n",
        "    for video_path in video_files:\n",
        "        video_name = os.path.basename(video_path).split(\".\")[0]\n",
        "        video_output_folder = os.path.join(output_folder, video_name)\n",
        "        os.makedirs(video_output_folder, exist_ok=True)\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        frame_interval = max(1, fps // frame_rate)\n",
        "\n",
        "        count = 0\n",
        "        frame_number = 0\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            if count % frame_interval == 0:\n",
        "                frame_filename = os.path.join(video_output_folder, f\"{video_name}_frame_{frame_number:04d}.jpg\")\n",
        "                cv2.imwrite(frame_filename, frame)\n",
        "                frame_number += 1\n",
        "            count += 1\n",
        "        cap.release()\n",
        "        print(f\"Extracted frames from {video_name}.\")\n",
        "\n",
        "# Run extraction\n",
        "extract_frames_from_videos(video_folder, output_frames)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w0KP7cfeyxG",
        "outputId": "88036bb5-42c0-41af-e3d7-e14ed4d5aff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 60 videos.\n",
            "Extracted frames from id7_0006.\n",
            "Extracted frames from id6_0004.\n",
            "Extracted frames from id6_0006.\n",
            "Extracted frames from id6_0000.\n",
            "Extracted frames from id6_0005.\n",
            "Extracted frames from id7_0009.\n",
            "Extracted frames from id7_0005.\n",
            "Extracted frames from id7_0002.\n",
            "Extracted frames from id6_0008.\n",
            "Extracted frames from id7_0000.\n",
            "Extracted frames from id6_0002.\n",
            "Extracted frames from id7_0004.\n",
            "Extracted frames from id6_0003.\n",
            "Extracted frames from id7_0003.\n",
            "Extracted frames from id7_0007.\n",
            "Extracted frames from id6_0009.\n",
            "Extracted frames from id7_0008.\n",
            "Extracted frames from id6_0007.\n",
            "Extracted frames from id6_0001.\n",
            "Extracted frames from id7_0001.\n",
            "Extracted frames from id9_0006.\n",
            "Extracted frames from id9_0004.\n",
            "Extracted frames from id9_0001.\n",
            "Extracted frames from id9_0002.\n",
            "Extracted frames from id9_0007.\n",
            "Extracted frames from id9_0009.\n",
            "Extracted frames from id9_0005.\n",
            "Extracted frames from id9_0000.\n",
            "Extracted frames from id9_0003.\n",
            "Extracted frames from id9_0008.\n",
            "Extracted frames from id9_id4_0002.\n",
            "Extracted frames from id9_id35_0004.\n",
            "Extracted frames from id9_id35_0007.\n",
            "Extracted frames from id9_id35_0001.\n",
            "Extracted frames from id9_id3_0000.\n",
            "Extracted frames from id9_id35_0002.\n",
            "Extracted frames from id9_id35_0000.\n",
            "Extracted frames from id9_id4_0004.\n",
            "Extracted frames from id9_id3_0007.\n",
            "Extracted frames from id9_id31_0006.\n",
            "Extracted frames from id9_id3_0002.\n",
            "Extracted frames from id9_id3_0001.\n",
            "Extracted frames from id9_id3_0006.\n",
            "Extracted frames from id9_id35_0005.\n",
            "Extracted frames from id9_id4_0000.\n",
            "Extracted frames from id9_id3_0004.\n",
            "Extracted frames from id9_id3_0008.\n",
            "Extracted frames from id9_id3_0009.\n",
            "Extracted frames from id9_id3_0005.\n",
            "Extracted frames from id9_id6_0006.\n",
            "Extracted frames from id9_id6_0000.\n",
            "Extracted frames from id9_id6_0001.\n",
            "Extracted frames from id9_id6_0002.\n",
            "Extracted frames from id9_id6_0008.\n",
            "Extracted frames from id9_id6_0005.\n",
            "Extracted frames from id9_id4_0005.\n",
            "Extracted frames from id9_id6_0007.\n",
            "Extracted frames from id9_id6_0009.\n",
            "Extracted frames from id9_id6_0004.\n",
            "Extracted frames from id9_id4_0006.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def preprocess_images(image_folder, output_folder, img_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Resize and normalize all images in a folder.\n",
        "    - image_folder: Path containing video frame folders.\n",
        "    - output_folder: Path to save preprocessed images.\n",
        "    - img_size: Target size for resizing.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for video_folder in os.listdir(image_folder):\n",
        "        video_path = os.path.join(image_folder, video_folder)\n",
        "        output_video_folder = os.path.join(output_folder, video_folder)\n",
        "        os.makedirs(output_video_folder, exist_ok=True)\n",
        "\n",
        "        for img_name in os.listdir(video_path):\n",
        "            img_path = os.path.join(video_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            img = cv2.resize(img, img_size)  # Resize\n",
        "            img = img / 255.0  # Normalize\n",
        "            img = (img * 255).astype(np.uint8)  # Convert back\n",
        "\n",
        "            cv2.imwrite(os.path.join(output_video_folder, img_name), img)\n",
        "\n",
        "    print(f\"Preprocessed images saved in {output_folder}\")\n",
        "\n",
        "# Run preprocessing\n",
        "preprocess_images(output_frames, output_preprocessed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFhLUoqze3_V",
        "outputId": "6988fd52-22a1-4653-90ce-e5e2f5dcdb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed images saved in /content/drive/MyDrive/Preprocessed frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_dataset(image_folder, output_base_folder, train_ratio=0.8, val_ratio=0.1):\n",
        "    \"\"\"\n",
        "    Split dataset into train, validation, and test sets.\n",
        "    - image_folder: Folder with processed frames.\n",
        "    - output_base_folder: Folder to store train, val, test sets.\n",
        "    - train_ratio: Percentage of data for training.\n",
        "    - val_ratio: Percentage of data for validation.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_base_folder, exist_ok=True)\n",
        "\n",
        "    for video_folder in os.listdir(image_folder):\n",
        "        video_path = os.path.join(image_folder, video_folder)\n",
        "        images = [f for f in os.listdir(video_path) if f.endswith('.jpg')]\n",
        "        random.shuffle(images)\n",
        "\n",
        "        train_split = int(train_ratio * len(images))\n",
        "        val_split = int((train_ratio + val_ratio) * len(images))\n",
        "\n",
        "        subsets = {\n",
        "            \"train\": images[:train_split],\n",
        "            \"val\": images[train_split:val_split],\n",
        "            \"test\": images[val_split:]\n",
        "        }\n",
        "\n",
        "        for subset, files in subsets.items():\n",
        "            subset_folder = os.path.join(output_base_folder, subset, video_folder)\n",
        "            os.makedirs(subset_folder, exist_ok=True)\n",
        "\n",
        "            for file in files:\n",
        "                src_path = os.path.join(video_path, file)\n",
        "                dst_path = os.path.join(subset_folder, file)\n",
        "                shutil.copy(src_path, dst_path)\n",
        "\n",
        "    print(\"Dataset split completed.\")\n",
        "\n",
        "# Run dataset split\n",
        "split_dataset(output_preprocessed, split_dataset_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvuKa-R3fTjy",
        "outputId": "430be4a2-4c85-4dce-a413-a63e2d461411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless facenet-pytorch numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSWGl3tBpFEM",
        "outputId": "db980082-5adb-4ebf-9e20-c37aaab8462c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (10.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.32.3)\n",
            "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.2.2)\n",
            "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (0.17.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "s3DzaXMYppUl",
        "outputId": "f35d5ef3-3a2a-4e47-adf9-822364019df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 10.2.0\n",
            "    Uninstalling pillow-10.2.0:\n",
            "      Successfully uninstalled pillow-10.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 11.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pillow-11.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "ca2c5f55ed214c458c33e25e697218d9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from facenet_pytorch import MTCNN\n",
        "\n",
        "#  Define paths\n",
        "VIDEO_FOLDER = \"/content/drive/MyDrive/deepfake\"\n",
        "OUTPUT_FOLDER = \"/content/drive/MyDrive/split_dataset_path\"\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "#  Initialize MTCNN\n",
        "mtcnn = MTCNN(keep_all=False, select_largest=True)\n",
        "\n",
        "def process_video(video_path, output_path, frame_limit=100):\n",
        "    \"\"\"Extract face from each frame and create a face-only video.\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    face_frames = []\n",
        "\n",
        "    while cap.isOpened() and frame_count < frame_limit:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert BGR to RGB for MTCNN\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Detect face and get bounding box\n",
        "        boxes, _ = mtcnn.detect(rgb_frame)\n",
        "\n",
        "        if boxes is not None and len(boxes) > 0:\n",
        "            x1, y1, x2, y2 = map(int, boxes[0])  # Get first detected face\n",
        "\n",
        "            # Ensure bounding box is within image bounds\n",
        "            h, w, _ = frame.shape\n",
        "            x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)\n",
        "\n",
        "            # Extract face from original BGR image\n",
        "            face = frame[y1:y2, x1:x2]\n",
        "\n",
        "            if face.size > 0:\n",
        "                # Resize for consistency\n",
        "                face_resized = cv2.resize(face, (160, 160), interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "                # Store extracted face frame\n",
        "                face_frames.append(face_resized)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Convert extracted faces into a new video\n",
        "    if len(face_frames) > 0:\n",
        "        height, width, _ = face_frames[0].shape\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        fps = 30  # Adjust FPS as needed\n",
        "        video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        for face in face_frames:\n",
        "            video_writer.write(face)\n",
        "\n",
        "        video_writer.release()\n",
        "        print(f\"Face-only video saved: {output_path}\")\n",
        "    else:\n",
        "        print(f\"No faces detected in {video_path}\")\n",
        "\n",
        "def process_all_videos(video_folder, output_folder, frame_limit=100):\n",
        "    \"\"\"Process all videos in a folder and generate face-only videos.\"\"\"\n",
        "    video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
        "\n",
        "    if not video_files:\n",
        "        print(\" No videos found in the folder!\")\n",
        "        return\n",
        "\n",
        "    for video_file in video_files:\n",
        "        video_path = os.path.join(video_folder, video_file)\n",
        "        output_path = os.path.join(output_folder, f\"processed_{video_file}\")\n",
        "\n",
        "        print(f\" Processing: {video_file}\")\n",
        "        process_video(video_path, output_path, frame_limit)\n",
        "\n",
        "#  Process all videos in the folder\n",
        "process_all_videos(VIDEO_FOLDER, OUTPUT_FOLDER)\n",
        "\n",
        "print(\" Face-only dataset creation complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt07s3penbCd",
        "outputId": "69108139-a625-4e9a-fbb1-1c2ab2266e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Processing: id7_0006.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id7_0006.mp4\n",
            " Processing: id6_0004.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id6_0004.mp4\n",
            " Processing: id6_0006.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id6_0006.mp4\n",
            " Processing: id6_0000.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id6_0000.mp4\n",
            " Processing: id6_0005.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id6_0005.mp4\n",
            " Processing: id7_0009.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id7_0009.mp4\n",
            " Processing: id7_0005.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id7_0005.mp4\n",
            " Processing: id7_0002.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id7_0002.mp4\n",
            " Processing: id6_0008.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id6_0008.mp4\n",
            " Processing: id7_0000.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id7_0000.mp4\n",
            " Processing: id6_0002.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id6_0002.mp4\n",
            " Processing: id7_0004.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id7_0004.mp4\n",
            " Processing: id6_0003.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id6_0003.mp4\n",
            " Processing: id7_0003.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id7_0003.mp4\n",
            " Processing: id7_0007.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id7_0007.mp4\n",
            " Processing: id6_0009.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id6_0009.mp4\n",
            " Processing: id7_0008.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id7_0008.mp4\n",
            " Processing: id6_0007.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id6_0007.mp4\n",
            " Processing: id6_0001.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id6_0001.mp4\n",
            " Processing: id7_0001.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id7_0001.mp4\n",
            " Processing: id9_0006.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_0006.mp4\n",
            " Processing: id9_0004.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_0004.mp4\n",
            " Processing: id9_0001.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_0001.mp4\n",
            " Processing: id9_0002.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_0002.mp4\n",
            " Processing: id9_0007.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_0007.mp4\n",
            " Processing: id9_0009.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_0009.mp4\n",
            " Processing: id9_0005.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_0005.mp4\n",
            " Processing: id9_0000.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_0000.mp4\n",
            " Processing: id9_0003.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_0003.mp4\n",
            " Processing: id9_0008.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_0008.mp4\n",
            " Processing: id9_id4_0002.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id4_0002.mp4\n",
            " Processing: id9_id35_0004.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id35_0004.mp4\n",
            " Processing: id9_id35_0007.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id35_0007.mp4\n",
            " Processing: id9_id35_0001.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id35_0001.mp4\n",
            " Processing: id9_id3_0000.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id3_0000.mp4\n",
            " Processing: id9_id35_0002.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id35_0002.mp4\n",
            " Processing: id9_id35_0000.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id35_0000.mp4\n",
            " Processing: id9_id4_0004.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id4_0004.mp4\n",
            " Processing: id9_id3_0007.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id3_0007.mp4\n",
            " Processing: id9_id31_0006.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id31_0006.mp4\n",
            " Processing: id9_id3_0002.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id3_0002.mp4\n",
            " Processing: id9_id3_0001.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id3_0001.mp4\n",
            " Processing: id9_id3_0006.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id3_0006.mp4\n",
            " Processing: id9_id35_0005.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id35_0005.mp4\n",
            " Processing: id9_id4_0000.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id4_0000.mp4\n",
            " Processing: id9_id3_0004.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id3_0004.mp4\n",
            " Processing: id9_id3_0008.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id3_0008.mp4\n",
            " Processing: id9_id3_0009.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id3_0009.mp4\n",
            " Processing: id9_id3_0005.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id3_0005.mp4\n",
            " Processing: id9_id6_0006.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id6_0006.mp4\n",
            " Processing: id9_id6_0000.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id6_0000.mp4\n",
            " Processing: id9_id6_0001.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id6_0001.mp4\n",
            " Processing: id9_id6_0002.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id6_0002.mp4\n",
            " Processing: id9_id6_0008.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id6_0008.mp4\n",
            " Processing: id9_id6_0005.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id6_0005.mp4\n",
            " Processing: id9_id4_0005.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id4_0005.mp4\n",
            " Processing: id9_id6_0007.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id6_0007.mp4\n",
            " Processing: id9_id6_0009.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id6_0009.mp4\n",
            " Processing: id9_id6_0004.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id6_0004.mp4\n",
            " Processing: id9_id4_0006.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/split_dataset_path/processed_id9_id4_0006.mp4\n",
            " Face-only dataset creation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define paths\n",
        "PROCESSED_VIDEO_FOLDER = \"/content/drive/MyDrive/split_dataset_path\"  # Use preprocessed videos\n",
        "OUTPUT_FOLDER = \"/content/drive/MyDrive/output_data\"\n",
        "\n",
        "# Define split ratios\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "# Create output directories\n",
        "train_folder = os.path.join(OUTPUT_FOLDER, \"train\")\n",
        "val_folder = os.path.join(OUTPUT_FOLDER, \"val\")\n",
        "test_folder = os.path.join(OUTPUT_FOLDER, \"test\")\n",
        "\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(val_folder, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "# Get all videos\n",
        "video_files = [f for f in os.listdir(PROCESSED_VIDEO_FOLDER) if f.endswith('.mp4')]\n",
        "\n",
        "# Shuffle for randomness\n",
        "random.shuffle(video_files)\n",
        "\n",
        "# Split indices\n",
        "total_videos = len(video_files)\n",
        "train_split = int(train_ratio * total_videos)\n",
        "val_split = int((train_ratio + val_ratio) * total_videos)\n",
        "\n",
        "# Assign to sets\n",
        "train_videos = video_files[:train_split]\n",
        "val_videos = video_files[train_split:val_split]\n",
        "test_videos = video_files[val_split:]\n",
        "\n",
        "# Function to move videos\n",
        "def move_videos(video_list, destination_folder):\n",
        "    for video in video_list:\n",
        "        src_path = os.path.join(PROCESSED_VIDEO_FOLDER, video)\n",
        "        dst_path = os.path.join(destination_folder, video)\n",
        "        shutil.move(src_path, dst_path)\n",
        "\n",
        "# Move videos to respective folders\n",
        "move_videos(train_videos, train_folder)\n",
        "move_videos(val_videos, val_folder)\n",
        "move_videos(test_videos, test_folder)\n",
        "\n",
        "print(\"Video dataset split completed!\")\n",
        "print(f\"Train: {len(train_videos)} videos\")\n",
        "print(f\"Validation: {len(val_videos)} videos\")\n",
        "print(f\"Test: {len(test_videos)} videos\")"
      ],
      "metadata": {
        "id": "VvQ-kW3DpUOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85342cd5-3499-4f82-9ca5-dd59c42203ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video dataset split completed!\n",
            "Train: 48 videos\n",
            "Validation: 6 videos\n",
            "Test: 6 videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DxmjQnfUyMhB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}